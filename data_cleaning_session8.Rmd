---
title: "data_cleaning"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library(dplyr)
library(tidyr)
library(readr)
```

```{r}
catch_original <- read_csv("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1")

##need this for using on windows
#catch_original <- read_csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1", method = "libcurl"))
```

```{r}
catch_data <- catch_original %>% 
  select(-All,-notesRegCode)
```

```{r}
catch_clean <- catch_data %>% 
  mutate(Chinook = as.numeric(Chinook))
##there is a typo in the Chinook column
```

```{r}
##Fix the Chinook typo

catch_clean <- catch_data %>% 
  mutate(Chinook = ifelse(Chinook == "I",1,Chinook)) %>% 
  mutate(Chinook = as.numeric(Chinook))
```
```{r}
catch_long <- catch_clean %>% 
  pivot_longer(cols = -c(Region, Year), names_to = "species", values_to = "catch")

catch_wide <- catch_long %>% 
  pivot_wider(names_from = "species", values_from = "catch")
```

```{r}
#make new catch column with total number of catches
#notice new column name is first
catch_long <- catch_long %>% 
  rename(catch_thousands = catch)

catch_long <- catch_long %>% 
  mutate(catch = catch_thousands*1000) %>% 
  select(-catch_thousands)
```

```{r}
mean_region <- catch_long %>% 
  group_by(Region) %>%
  summarise(catch_mean = mean(catch)) %>% 
  arrange(desc(catch_mean))
#group_by() by itself produces the same dataframe, but dplyr "remembers" that the next operation will be group-wise. 

# n() counts # of rows in grouping variable
n_region <- catch_long %>% 
  group_by(Region) %>% 
  summarise(n = n())
```
```{r}
SSE_catch <- catch_long %>%
  filter(Region == "SSE")
```

```{r}
region_defs <- read_csv("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.303.1") %>% 
    select(code, mgmtArea)

catch_joined <- left_join(catch_long, region_defs, by=c("Region" = "code"))
```

```{r}
sites_df <- data.frame(site = c("HAW-101",
                                "HAW-103",
                                "OAH-320",
                                "OAH-219",
                                "MAI-039"),
                       stringsAsFactors = FALSE)

sites_df %>% 
  separate(site, c("island", "site_number"), "-")
```

```{r}
dates_df <- data.frame(year = c("1930",
                                "1930",
                                "1930"),
                       month = c("12",
                                "12",
                                "12"),
                       day = c("14",
                               "15",
                               "16"),
                       stringsAsFactors = FALSE)

dates_df %>% 
  unite(date, year, month, day, sep = "-")
```
```{r}
##this is all above data cleaning in one pipe
catch_original <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1", method = "libcurl"),
                  stringsAsFactors = FALSE)
region_defs <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.303.1", method = "libcurl"),
                        stringsAsFactors = FALSE) %>% 
    select(code, mgmtArea)

mean_region <- catch_original %>%
  select(-All, -notesRegCode) %>% 
  mutate(Chinook = ifelse(Chinook == "I", 1, Chinook)) %>% 
  mutate(Chinook = as.numeric(Chinook)) %>% 
  pivot_longer(-c(Region, Year), names_to = "species", values_to = "catch") %>%
  mutate(catch = catch*1000) %>% 
  group_by(Region) %>% 
  summarize(mean_catch = mean(catch)) %>% 
  left_join(region_defs, by = c("Region" = "code"))

head(mean_region)
```


